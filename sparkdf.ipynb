{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xKUiifPp32x"
   },
   "source": [
    "# SIADS 516: Homework 3\n",
    "Version 2.0.20201020.1\n",
    "### Dr. Chris Teplovs, School of Information, University of Michigan\n",
    "<small><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a>This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework assignment builds on the Spark DataFrame material we covered in class.\n",
    "You will be using a compressed version of the Yelp Academic Dataset.  The data set is provided for you in the data/yelp-academic sub-folder of this notebook's directory and you should not need to download it again if you're working on the Coursera hosted notebook environment.\n",
    "\n",
    "You might want to refer to the lecture companion notebooks (in workspace-files/resources/lecture_notebooks or equivalently via Coursera as \"Ungraded Lab: Spark Core Demo\" and \"Ungraded Lab: Spark SQL Demo) for hints about libraries to import, how to set up a SparkSession, and how to read data files.\n",
    "\n",
    "You will notice that there are a **lot** of reviews.  You might want to work off a small sample (i.e. use the sample() function in Spark) to work on a reduced size dataset while you're developing your solution.\n",
    "\n",
    "**You should take care to document your work, preferably using markdown blocks. In-code commenting is also \n",
    "a good idea.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q1: How many users have received more than 5000 cool votes?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('SIADS 516 Homework 3') \\\n",
    "    .getOrCreate() \n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "business = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_business.json.gz')\n",
    "checkin = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_checkin.json.gz')\n",
    "review = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_review.json.gz')\n",
    "tip = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_tip.json.gz')\n",
    "user = spark.read.json('../non_auto_assignments/data/yelp_academic/yelp_academic_dataset_user.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import other required packages\n",
    "from pyspark.sql.functions import explode, udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import * \n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_cool: long (nullable = true)\n",
      " |-- compliment_cute: long (nullable = true)\n",
      " |-- compliment_funny: long (nullable = true)\n",
      " |-- compliment_hot: long (nullable = true)\n",
      " |-- compliment_list: long (nullable = true)\n",
      " |-- compliment_more: long (nullable = true)\n",
      " |-- compliment_note: long (nullable = true)\n",
      " |-- compliment_photos: long (nullable = true)\n",
      " |-- compliment_plain: long (nullable = true)\n",
      " |-- compliment_profile: long (nullable = true)\n",
      " |-- compliment_writer: long (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- elite: string (nullable = true)\n",
      " |-- fans: long (nullable = true)\n",
      " |-- friends: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- yelping_since: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# showing the schema from user DataFrame\n",
    "user.printSchema()\n",
    "# assign condition to extract rows that users received more than 5000 'cool' compliments\n",
    "res1 = user.filter(user['compliment_cool'] > 5000).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 79 users who received more than 5000 'cool' compliments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q2: What are the top 10 most useful positive reviews?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview schema of review DataFrame\n",
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|ujmEBvifdJM6h6RLv...|   0|2013-05-07 04:34:36|    1|Q1sbwvVQXV2734tPg...|  1.0|Total bill for th...|     6|hG7b0MtEbXx5QzbzE...|\n",
      "|NZnhc2sEQy3RmzKTZ...|   0|2017-01-14 21:30:33|    0|GJXCdrto3ASJOqKeV...|  5.0|I *adore* Travis ...|     0|yXQM5uF2jS6es16SJ...|\n",
      "|WTqjgwHlXbSFevF32...|   0|2016-11-09 20:09:03|    0|2TzJjDVDEuAW6MR5V...|  5.0|I have to say tha...|     3|n6-Gk65cPZL6Uz8qR...|\n",
      "|ikCg8xy5JIg_NGPx-...|   0|2018-01-09 20:56:38|    0|yi0R0Ugj_xUx_Nek0...|  5.0|Went in for a lun...|     0|dacAIZ6fTM6mqwW5u...|\n",
      "|b1b1eb3uo-w561D0Z...|   0|2018-01-30 23:07:38|    0|11a8sVPMUFtaC7_AB...|  1.0|Today was my seco...|     7|ssoyf2_x0EQMed6fg...|\n",
      "|eU_713ec6fTGNO4Be...|   0|2013-01-20 13:25:59|    0|fdiNeiN_hoCxCMy2w...|  4.0|I'll be the first...|     0|w31MKYsNFMrjhWxxA...|\n",
      "|3fw2X5bZYeW9xCz_z...|   5|2016-05-07 01:21:02|    4|G7XHMxG0bx9oBJNEC...|  3.0|Tracy dessert had...|     5|jlu4CztcSxrKx56ba...|\n",
      "|zvO-PJCpNk4fgAVUn...|   1|2010-10-05 19:12:35|    1|8e9HxxLjjqc9ez5ez...|  1.0|This place has go...|     3|d6xvYpyzcfbF_AZ8v...|\n",
      "|b2jN2mm9Wf3RcrZCg...|   0|2015-01-18 14:04:18|    0|qrffudO73zsslZbe8...|  2.0|I was really look...|     1|sG_h0dIzTKWa3Q6fm...|\n",
      "|oxwGyA17NL6c5t1Et...|   1|2012-02-29 21:52:43|    0|RS_GTIT6836bCaPy6...|  3.0|It's a giant Best...|     1|nMeCE5-xsdleyxYuN...|\n",
      "|8mIrX_LrOnAqWsB5J...|   0|2011-11-30 02:11:15|    0|kbtscdyz6lvrtGjD1...|  4.0|Like walking back...|     0|FIk4lQQu1eTe2EpzQ...|\n",
      "|mRUVMJkUGxrByzMQ2...|   0|2017-12-15 23:27:08|    1|-I5umRTkhw15RqpKM...|  1.0|Walked in around ...|     0|-mA3-1mN4JIEkqOtd...|\n",
      "|FxLfqxdYPA6Z85PFK...|   0|2016-05-07 01:36:53|    0|Z7wgXp98wYB57QdRY...|  4.0|Wow. So surprised...|     0|GYNnVehQeXjty0xH7...|\n",
      "|LUN6swQYa4xJKaM_U...|   0|2018-04-27 20:25:26|    0|qlXw1JQ0UodW7qrmV...|  4.0|Michael from Red ...|     0|bAhqAPoWaZYcyYi7b...|\n",
      "|AakkkTuGZA2KBodKi...|   0|2012-07-16 00:37:14|    1|JVcjMhlavKKn3UIt9...|  1.0|I cannot believe ...|     1|TpyOT5E16YASd7EWj...|\n",
      "|YvrylyuWgbP90RgMq...|   0|2017-04-07 21:27:49|    0|svK3nBU7Rk8VfGorl...|  5.0|You can't really ...|     0|NJlxGtouq06hhC7sS...|\n",
      "|NyLYY8q1-H3hfsTwu...|   0|2015-01-03 22:47:34|    0|1wVA2-vQIuW_ClmXk...|  4.0|Great lunch today...|     0|86J5DwcFk4f4In1Vx...|\n",
      "|cHdJXLlKNWixBXpDw...|   1|2015-04-01 16:30:00|    7|6BnQwlxRn7ZuWdzni...|  3.0|I love chinese fo...|     1|JSrP-dUmLlwZiI7Dp...|\n",
      "|6lj2BJ4tJeu7db5as...|   0|2017-05-26 01:23:19|    0|rEITo90tpyKmEfNDp...|  5.0|We've been a huge...|     0|6Fz_nus_OG4gar721...|\n",
      "|y-Iw6dZflNix4BdwI...|   0|2014-06-27 21:19:23|    0|4bUyL7lzoWzDZaJET...|  3.0|Good selection of...|     0|_N7Ndn29bpll_961o...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview data of the DataFrame\n",
    "review.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by descending useful count\n",
    "review_desc = review.orderBy('useful', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 reviews' text, review_id, useful counts\n",
    "res2 = review_desc.select('review_id', 'text', 'useful' ).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|           review_id|                text|useful|\n",
      "+--------------------+--------------------+------+\n",
      "|4ZN5ZWVoGd8er9giA...|Dinner for 1.\n",
      "\n",
      "- ...|  1241|\n",
      "|A8mLBytNM2zmjHgSp...|In retrospect, I ...|  1122|\n",
      "|ZmEtySx0W_RSv07aY...|This restaurant i...|   970|\n",
      "|EYbuFrEnVkVdavuRm...|This is the secon...|   846|\n",
      "|O1YX1g7Wbf0rmcoud...|I actually suspec...|   808|\n",
      "|aTLCBP_6lrCs2Qo3k...|\"scary that peopl...|   781|\n",
      "|EluaWiwRr0VhTwJe9...|I really wanted t...|   694|\n",
      "|oo7W2IgyMMiraml-s...|A few years ago a...|   668|\n",
      "|QovoEUcs34yvCCm5u...|I'd put zero star...|   650|\n",
      "|69suGHxR3PVxicAgm...|We were very disa...|   578|\n",
      "+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corresponding review ids of the top 10 useful reviews\n",
    "res2_ids_l = res2.select('review_id').collect()\n",
    "#corresponding text of the top 10 useful reviews\n",
    "res2_text_l = res2.select('text').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 'most useful' reviews can be found in the spark dataframe res2, with corresponding information. pure text can be found in python list res2_text_l; review id can be found in python list res2_ids_l."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q3: During what hour of the day do most checkins occur?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(date='2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016-10-15 02:45:18, 2016-11-18 01:54:50, 2017-04-20 18:39:06, 2017-05-03 17:58:02')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview checkin DataFrame schema\n",
    "checkin.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(date='2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016-10-15 02:45:18, 2016-11-18 01:54:50, 2017-04-20 18:39:06, 2017-05-03 17:58:02')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview checkin DataFrame entry\n",
    "checkin.select('date').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the checkin dataframe\n",
    "\n",
    "datesplit = udf(lambda x: x.split(','), ArrayType(StringType()))\n",
    "\n",
    "checkin_exploded = checkin.select(datesplit('date').alias('date_list')).withColumn('checkin_record', explode('date_list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           date_list|      checkin_record|\n",
      "+--------------------+--------------------+\n",
      "|[2016-04-26 19:49...| 2016-04-26 19:49:16|\n",
      "|[2016-04-26 19:49...| 2016-08-30 18:36:57|\n",
      "|[2016-04-26 19:49...| 2016-10-15 02:45:18|\n",
      "|[2016-04-26 19:49...| 2016-11-18 01:54:50|\n",
      "|[2016-04-26 19:49...| 2017-04-20 18:39:06|\n",
      "|[2016-04-26 19:49...| 2017-05-03 17:58:02|\n",
      "|[2011-06-04 18:22...| 2011-06-04 18:22:23|\n",
      "|[2011-06-04 18:22...| 2011-07-23 23:51:33|\n",
      "|[2011-06-04 18:22...| 2012-04-15 01:07:50|\n",
      "|[2011-06-04 18:22...| 2012-05-06 23:08:42|\n",
      "|[2011-06-04 18:22...| 2012-06-08 22:43:12|\n",
      "|[2011-06-04 18:22...| 2012-08-06 23:20:52|\n",
      "|[2011-06-04 18:22...| 2012-08-19 18:30:44|\n",
      "|[2011-06-04 18:22...| 2013-01-27 23:49:51|\n",
      "|[2011-06-04 18:22...| 2013-03-01 01:22:29|\n",
      "|[2011-06-04 18:22...| 2013-03-23 21:53:47|\n",
      "|[2011-06-04 18:22...| 2013-03-24 01:11:51|\n",
      "|[2011-06-04 18:22...| 2013-05-20 00:12:25|\n",
      "|[2011-06-04 18:22...| 2013-06-29 22:50:57|\n",
      "|[2011-06-04 18:22...| 2013-07-01 15:58:04|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkin_exploded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|<lambda>(checkin_record)|\n",
      "+------------------------+\n",
      "|                      19|\n",
      "|                      18|\n",
      "|                      02|\n",
      "|                      01|\n",
      "|                      18|\n",
      "|                      17|\n",
      "|                      18|\n",
      "|                      23|\n",
      "|                      01|\n",
      "|                      23|\n",
      "|                      22|\n",
      "|                      23|\n",
      "|                      18|\n",
      "|                      23|\n",
      "|                      01|\n",
      "|                      21|\n",
      "|                      01|\n",
      "|                      00|\n",
      "|                      22|\n",
      "|                      15|\n",
      "+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract hour from checkin Dataframe\n",
    "\n",
    "get_hour = udf(lambda x: re.findall(r'\\s(\\d\\d):', x)[0], StringType())\n",
    "checkin_exploded.select(get_hour('checkin_record')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = checkin_exploded.select(get_hour('checkin_record').alias('hours'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hours='07', count=231417),\n",
       " Row(hours='15', count=617830),\n",
       " Row(hours='11', count=111769),\n",
       " Row(hours='01', count=1561788),\n",
       " Row(hours='22', count=1257437),\n",
       " Row(hours='16', count=852076),\n",
       " Row(hours='18', count=1272108),\n",
       " Row(hours='00', count=1491176),\n",
       " Row(hours='17', count=1006102),\n",
       " Row(hours='09', count=100568),\n",
       " Row(hours='05', count=485129),\n",
       " Row(hours='19', count=1502271),\n",
       " Row(hours='23', count=1344117),\n",
       " Row(hours='08', count=151065),\n",
       " Row(hours='03', count=1078939),\n",
       " Row(hours='02', count=1411255),\n",
       " Row(hours='06', count=321764),\n",
       " Row(hours='20', count=1350195),\n",
       " Row(hours='10', count=88486),\n",
       " Row(hours='12', count=178910),\n",
       " Row(hours='04', count=747453),\n",
       " Row(hours='13', count=270145),\n",
       " Row(hours='21', count=1238808),\n",
       " Row(hours='14', count=418340)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by hours and count frequency for each hour\n",
    "res3.groupBy('hours').count().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hour-wise, most checkins occur at 0100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q4: Sentiment analysis</font>\n",
    "\n",
    "a. List the 50 most common non-stopword words that are unique to *positive* reviews.\n",
    "b. List the 50 most common non-stopword words that are unique to *negative* reviews.\n",
    "\n",
    "You can use the stopword list that was introduced in the lecture materials or you can \n",
    "find/devise one of your own.\n",
    "\n",
    "You will need to define what constitutes a positive review and what constitutes a negative review.  We highly recommend that you use the number of stars to figure this out.  Be sure to provide a rationale for your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the following two reviews:\n",
    "\n",
    "* Positive: The meal was great, and the service was the best we ever experienced.\n",
    "* Negative: The meal was awful.  It was the worst thing we ever experienced.\n",
    "\n",
    "Assume our stopwords are {'the','was','and','the','was','we','it'}\n",
    "\n",
    "* Positive unique: {'great', 'service', 'best'}\n",
    "\n",
    "* Negative unique: {'awful', 'worst', 'thing'}\n",
    "\n",
    "In this example, each unique word occurs just once, so the concept of \"top 50\" doesn't make sense.  For your data, you'll need to count the number of times each unique word occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. List the 50 most common non-stopword words that are unique to positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|I *adore* Travis ...|\n",
      "|I have to say tha...|\n",
      "|Went in for a lun...|\n",
      "|I'll be the first...|\n",
      "|Like walking back...|\n",
      "|Wow. So surprised...|\n",
      "|Michael from Red ...|\n",
      "|You can't really ...|\n",
      "|Great lunch today...|\n",
      "|We've been a huge...|\n",
      "|Our family LOVES ...|\n",
      "|If you are lookin...|\n",
      "|The food is alway...|\n",
      "|Pick any meat on ...|\n",
      "|Great food, great...|\n",
      "|PlumbSmart provid...|\n",
      "|their pettuccine ...|\n",
      "|ended up here bec...|\n",
      "|Best chinese rest...|\n",
      "|This place epitom...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#According to the yelp site- write a review page, select 3 stars means 'ok', while 4 stars mean 'good' and 5 stars mean 'great'. Therefore we narrow down to reviews with 4-5 stars ratings as positive reviews. \n",
    "res4a_1 = review.filter(review['stars'] > 3.0)\n",
    "res4a_1.select('text').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopword transformer from pyspark.ml as stopword filtering function\n",
    "Remover_res4 = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|            filtered|\n",
      "+--------------------+--------------------+\n",
      "|[i, adore, travis...|[adore, travis, h...|\n",
      "|[i, have, to, say...|[say, office, rea...|\n",
      "|[went, in, for, a...|[went, lunch, ste...|\n",
      "|[ill, be, the, fi...|[ill, first, admi...|\n",
      "|[like, walking, b...|[like, walking, b...|\n",
      "|[wow, so, surpris...|[wow, surprised, ...|\n",
      "|[michael, from, r...|[michael, red, ca...|\n",
      "|[you, cant, reall...|[cant, really, fi...|\n",
      "|[great, lunch, to...|[great, lunch, to...|\n",
      "|[weve, been, a, h...|[weve, huge, slim...|\n",
      "|[our, family, lov...|[family, loves, f...|\n",
      "|[if, you, are, lo...|[looking, best, p...|\n",
      "|[the, food, is, a...|[food, always, go...|\n",
      "|[pick, any, meat,...|[pick, meat, plan...|\n",
      "|[great, food, gre...|[great, food, gre...|\n",
      "|[plumbsmart, prov...|[plumbsmart, prov...|\n",
      "|[their, pettuccin...|[pettuccine, fres...|\n",
      "|[ended, up, here,...|[ended, raku, clo...|\n",
      "|[best, chinese, r...|[best, chinese, r...|\n",
      "|[this, place, epi...|[place, epitomize...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create lists of words, filtered with stop words, remove punctuations and clean up/ standardize\n",
    "textsplit = udf(lambda x: re.sub(r'[^\\w\\s]', '', x).lower().split(), ArrayType(StringType()))\n",
    "res4a_2 = res4a_1.select(textsplit('text').alias('words'))\n",
    "res4a_3 = Remover_res4.transform(res4a_2)                 \n",
    "res4a_3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='great', count=2403454),\n",
       " Row(word='place', count=2113929),\n",
       " Row(word='good', count=2099933),\n",
       " Row(word='food', count=1969159),\n",
       " Row(word='service', count=1413577),\n",
       " Row(word='time', count=1350757),\n",
       " Row(word='like', count=1275360),\n",
       " Row(word='one', count=1199603),\n",
       " Row(word='get', count=1194370),\n",
       " Row(word='back', count=1107119),\n",
       " Row(word='really', count=1069876),\n",
       " Row(word='go', count=1018052),\n",
       " Row(word='also', count=989381),\n",
       " Row(word='best', count=947167),\n",
       " Row(word='love', count=891038),\n",
       " Row(word='always', count=854365),\n",
       " Row(word='nice', count=841867),\n",
       " Row(word='well', count=806333),\n",
       " Row(word='friendly', count=797308),\n",
       " Row(word='amazing', count=775425),\n",
       " Row(word='definitely', count=754587),\n",
       " Row(word='staff', count=737547),\n",
       " Row(word='ive', count=735655),\n",
       " Row(word='delicious', count=722219),\n",
       " Row(word='got', count=705668),\n",
       " Row(word='us', count=690800),\n",
       " Row(word='im', count=673208),\n",
       " Row(word='try', count=643972),\n",
       " Row(word='even', count=640415),\n",
       " Row(word='little', count=619669),\n",
       " Row(word='dont', count=604817),\n",
       " Row(word='first', count=595459),\n",
       " Row(word='recommend', count=594273),\n",
       " Row(word='chicken', count=568246),\n",
       " Row(word='restaurant', count=567179),\n",
       " Row(word='come', count=553816),\n",
       " Row(word='came', count=550285),\n",
       " Row(word='made', count=538190),\n",
       " Row(word='menu', count=532009),\n",
       " Row(word='ordered', count=530132),\n",
       " Row(word='experience', count=523964),\n",
       " Row(word='much', count=511308),\n",
       " Row(word='went', count=502952),\n",
       " Row(word='make', count=500856),\n",
       " Row(word='everything', count=492559),\n",
       " Row(word='new', count=484116),\n",
       " Row(word='fresh', count=477891),\n",
       " Row(word='people', count=476182),\n",
       " Row(word='order', count=470612),\n",
       " Row(word='right', count=446951)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a list based on top counts from the words\n",
    "res4a_4 = res4a_3.select('filtered').withColumn('word', explode('filtered'))\\\n",
    ".groupBy('word')\\\n",
    ".count()\\\n",
    ".sort('count', ascending=False)\\\n",
    ".take(50)\n",
    "# View the list of most non-stop words related to positive reviews\n",
    "res4a_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great', 'place', 'good', 'food', 'service', 'time', 'like', 'one', 'get', 'back', 'really', 'go', 'also', 'best', 'love', 'always', 'nice', 'well', 'friendly', 'amazing', 'definitely', 'staff', 'ive', 'delicious', 'got', 'us', 'im', 'try', 'even', 'little', 'dont', 'first', 'recommend', 'chicken', 'restaurant', 'come', 'came', 'made', 'menu', 'ordered', 'experience', 'much', 'went', 'make', 'everything', 'new', 'fresh', 'people', 'order', 'right']\n"
     ]
    }
   ],
   "source": [
    "# Clean up: answer for 4(a)\n",
    "res4a = []\n",
    "for i in res4a_4:\n",
    "    w = re.findall(r\"'([^']*)'\", str(i))[0]\n",
    "    res4a.append(w)\n",
    "print(res4a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. List the 50 most common non-stopword words that are unique to negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your interpretation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Total bill for th...|\n",
      "|Today was my seco...|\n",
      "|This place has go...|\n",
      "|I was really look...|\n",
      "|Walked in around ...|\n",
      "|I cannot believe ...|\n",
      "|Unfortunately, I ...|\n",
      "|if i can give thi...|\n",
      "|This review is in...|\n",
      "|I tried this plac...|\n",
      "|Love this place d...|\n",
      "|Came here on a Th...|\n",
      "|Went here last we...|\n",
      "|They keep there a...|\n",
      "|Met a friend for ...|\n",
      "|We had dinner at ...|\n",
      "|I am years out fr...|\n",
      "|I've never experi...|\n",
      "|Took my kids here...|\n",
      "|Sadly this place ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#According to the yelp site- write a review page, select 3 stars means 'ok', while 4 stars mean 'good' and 5 stars mean 'great'. Therefore we narrow down to reviews with \"below 3 stars\" ratings as negative reviews. \n",
    "res4b_1 = review.filter(review['stars'] < 3.0)\n",
    "res4b_1.select('text').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|            filtered|\n",
      "+--------------------+--------------------+\n",
      "|[total, bill, for...|[total, bill, hor...|\n",
      "|[today, was, my, ...|[today, second, t...|\n",
      "|[this, place, has...|[place, gone, hil...|\n",
      "|[i, was, really, ...|[really, looking,...|\n",
      "|[walked, in, arou...|[walked, around, ...|\n",
      "|[i, cannot, belie...|[believe, things,...|\n",
      "|[unfortunately, i...|[unfortunately, m...|\n",
      "|[if, i, can, give...|[give, place, sta...|\n",
      "|[this, review, is...|[review, regards,...|\n",
      "|[i, tried, this, ...|[tried, place, gi...|\n",
      "|[love, this, plac...|[love, place, dow...|\n",
      "|[came, here, on, ...|[came, thursday, ...|\n",
      "|[went, here, last...|[went, last, week...|\n",
      "|[they, keep, ther...|[keep, appointmen...|\n",
      "|[met, a, friend, ...|[met, friend, din...|\n",
      "|[we, had, dinner,...|[dinner, bellagio...|\n",
      "|[i, am, years, ou...|[years, surgery, ...|\n",
      "|[ive, never, expe...|[ive, never, expe...|\n",
      "|[took, my, kids, ...|[took, kids, hang...|\n",
      "|[sadly, this, pla...|[sadly, place, so...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create lists of words, filtered with stop words, remove punctuations and clean up/ standardize\n",
    "res4b_2 = res4b_1.select(textsplit('text').alias('words'))\n",
    "res4b_3 = Remover_res4.transform(res4b_2)                 \n",
    "res4b_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='food', count=867937),\n",
       " Row(word='get', count=744415),\n",
       " Row(word='place', count=731189),\n",
       " Row(word='service', count=718773),\n",
       " Row(word='one', count=710177),\n",
       " Row(word='like', count=697995),\n",
       " Row(word='time', count=696904),\n",
       " Row(word='back', count=684846),\n",
       " Row(word='good', count=557466),\n",
       " Row(word='us', count=549496),\n",
       " Row(word='go', count=521938),\n",
       " Row(word='even', count=515453),\n",
       " Row(word='dont', count=502146),\n",
       " Row(word='said', count=487167),\n",
       " Row(word='never', count=471824),\n",
       " Row(word='didnt', count=465724),\n",
       " Row(word='told', count=449468),\n",
       " Row(word='got', count=436888),\n",
       " Row(word='order', count=396105),\n",
       " Row(word='came', count=372923),\n",
       " Row(word='asked', count=365851),\n",
       " Row(word='went', count=361005),\n",
       " Row(word='really', count=356375),\n",
       " Row(word='ordered', count=349025),\n",
       " Row(word='minutes', count=339839),\n",
       " Row(word='im', count=330615),\n",
       " Row(word='people', count=326834),\n",
       " Row(word='first', count=313230),\n",
       " Row(word='going', count=290470),\n",
       " Row(word='know', count=288722),\n",
       " Row(word='also', count=280053),\n",
       " Row(word='2', count=276552),\n",
       " Row(word='another', count=276485),\n",
       " Row(word='come', count=270184),\n",
       " Row(word='customer', count=266524),\n",
       " Row(word='bad', count=265143),\n",
       " Row(word='two', count=264580),\n",
       " Row(word='took', count=260484),\n",
       " Row(word='way', count=256921),\n",
       " Row(word='experience', count=252728),\n",
       " Row(word='better', count=251710),\n",
       " Row(word='well', count=249075),\n",
       " Row(word='much', count=248795),\n",
       " Row(word='restaurant', count=247604),\n",
       " Row(word='take', count=246159),\n",
       " Row(word='still', count=244507),\n",
       " Row(word='called', count=243927),\n",
       " Row(word='make', count=243844),\n",
       " Row(word='give', count=242578),\n",
       " Row(word='great', count=238320)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a list based on top counts from the words\n",
    "res4b_4 = res4b_3.select('filtered').withColumn('word', explode('filtered'))\\\n",
    ".groupBy('word')\\\n",
    ".count()\\\n",
    ".sort('count', ascending=False)\\\n",
    ".take(50)\n",
    "# View the list of most non-stop words related to negative reviews\n",
    "res4b_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'get', 'place', 'service', 'one', 'like', 'time', 'back', 'good', 'us', 'go', 'even', 'dont', 'said', 'never', 'didnt', 'told', 'got', 'order', 'came', 'asked', 'went', 'really', 'ordered', 'minutes', 'im', 'people', 'first', 'going', 'know', 'also', '2', 'another', 'come', 'customer', 'bad', 'two', 'took', 'way', 'experience', 'better', 'well', 'much', 'restaurant', 'take', 'still', 'called', 'make', 'give', 'great']\n"
     ]
    }
   ],
   "source": [
    "# Clean up: answer for 4(b)\n",
    "res4b = []\n",
    "for i in res4b_4:\n",
    "    w = re.findall(r\"'([^']*)'\", str(i))[0]\n",
    "    res4b.append(w)\n",
    "print(res4b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
